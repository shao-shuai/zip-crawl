Title: Senior Hadoop Developer w/ Java & Multi-threading
Company: TEKREQS, Inc.
Location: New York, NY
Type: Full-Time

Senior Hadoop Developer (4 Openings)
Have the opportunity to join a lead innovator in the Low-Latency Analytics software product space with offices in New York City, Boston, and San Francisco working as a Senior Hadoop Developer on their Data Platform team, where you will on problems that are common yet complex. This software product firm's software/application teams face challenges of large-scale data storage, low-latency retrievals, high volume requests and high availability over a distributed systems environment. The Data Platform team creates standardized solutions to these problems by building Core Services and technology frameworks for enterprise-wide use by these teams.
As an experienced Hadoop Developer/Architect, you will help the firm refresh and evolve many facets of their Enterprise Data Platform and Analytics Infrastructure for three major systems, which are the Data Platform (DP), Pricing History and Query Language (QL) systems. The Data Platform (DP) is an initiative to help standardize the storage backends and structure data flows across the firm's systems to improve discoverability and data provenance. Pricing History is the firm's canonical end of day Time Series datastore. The Query Language (QL) is a Distributed Analytics framework that allows internal and external users to express complex data retrieval, analytics and screening criteria.
All of this Low-Latency Analytics product firm's data flows through these systems. You'll gain exposure to large-scale data sets and how they're used while building high performance, low-latency, scalable software for these Core Infrastructure initiatives. Much of the firm's software/applications are being built on top of Open Source Hadoop technologies, so there are plenty of avenues to innovate and contribute to the Open Source community.
Responsibilities:
- Take ownership of a component of the Query Language (QL), Pricing History or Data Platform (DP) platform.
- Interact with development teams across the firm and understand their software/application requirements and data access patterns.
- Design and develop Distributed systems that meet the firm's low latency, volume, storage and scale expectations.
- Participate in daily scrum meetings and sprint sessions to help influence architectural decisions.
Qualifications:
- 5+ years of core Java programming experience with strong multi-threaded programming experience.
- 3+ years of experience working with the Hadoop ecosystem (HDFS, MapReduce).
- 3+ years of NoSQL data stores experience (preferably HBase or Cassandra)
- Experience developing, enhancing and maintaining high throughput, low-latency Hadoop systems in a mission-critical production environment
- Experience working in a Test Driven (TDD) and Agile development environment
Desired Skills:
- Experience enhancing and maintaining mission-critical software in a fast-paced environment.
- Experience with Spark, Kafka, Oozie, Zookeeper, Flume or Storm
